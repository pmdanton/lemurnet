{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LemurNet\n",
    "For explanations on this notebook, check out https://www.lemurnet.org/blog_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.11.0\n",
      "Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import keras\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.utils import Sequence\n",
    "from keras import layers, models, callbacks, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to your dataset, must contian subfolders \"train\" and \"validation\"\n",
    "# each of which must contain one folder per class\n",
    "base_dir = \"/path/to/your/dataset\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "classes = os.listdir(train_dir)\n",
    "classes.sort()\n",
    "N_CLASSES = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenetv2\n",
    "\n",
    "preprocess_input = mobilenetv2.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "     rotation_range=20,\n",
    "     width_shift_range=0.2,\n",
    "     height_shift_range=0.2,\n",
    "     shear_range=0.1,\n",
    "     zoom_range=0.2,\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "conv_base = mobilenetv2.MobileNetV2(\n",
    "    include_top=False, pooling=\"avg\", input_shape=(224, 224, 3), weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7599 images belonging to 35 classes.\n",
      "Found 2052 images belonging to 35 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=conv_base.input_shape[1:-1],\n",
    "    batch_size=17,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=conv_base.input_shape[1:-1],\n",
    "    batch_size=27,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = conv_base.output\n",
    "features = layers.Dropout(0.5, name=\"dropout\")(features)\n",
    "predictions = layers.Dense(N_CLASSES, activation=\"softmax\", name=\"predictions\")(\n",
    "    features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(conv_base.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        \"lemurnet_mobilenet.h5\", monitor=\"val_acc\", verbose=0, save_best_only=True\n",
    "    ),\n",
    "    callbacks.EarlyStopping(monitor=\"val_acc\", patience=3, verbose=1),\n",
    "    callbacks.TensorBoard(log_dir=\"./logs\", write_images=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_acc\", factor=0.8, patience=1, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "447/447 [==============================] - 113s 253ms/step - loss: 2.9519 - acc: 0.2523 - val_loss: 2.9603 - val_acc: 0.2515\n",
      "Epoch 2/50\n",
      "447/447 [==============================] - 100s 224ms/step - loss: 2.1875 - acc: 0.4118 - val_loss: 2.9665 - val_acc: 0.2641\n",
      "Epoch 3/50\n",
      "447/447 [==============================] - 101s 226ms/step - loss: 2.1855 - acc: 0.4256 - val_loss: 2.8611 - val_acc: 0.3367\n",
      "Epoch 4/50\n",
      "447/447 [==============================] - 97s 218ms/step - loss: 2.1238 - acc: 0.4380 - val_loss: 2.8970 - val_acc: 0.3221\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 5/50\n",
      "447/447 [==============================] - 100s 224ms/step - loss: 2.0878 - acc: 0.4526 - val_loss: 3.0802 - val_acc: 0.3294\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 6/50\n",
      "447/447 [==============================] - 99s 222ms/step - loss: 1.9888 - acc: 0.4698 - val_loss: 2.6814 - val_acc: 0.3860\n",
      "Epoch 7/50\n",
      "447/447 [==============================] - 101s 226ms/step - loss: 1.9801 - acc: 0.4703 - val_loss: 2.9243 - val_acc: 0.3246\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 8/50\n",
      "447/447 [==============================] - 103s 229ms/step - loss: 2.0521 - acc: 0.4684 - val_loss: 2.3658 - val_acc: 0.4162\n",
      "Epoch 9/50\n",
      "447/447 [==============================] - 101s 227ms/step - loss: 1.8236 - acc: 0.4978 - val_loss: 2.5901 - val_acc: 0.4230\n",
      "Epoch 10/50\n",
      "447/447 [==============================] - 99s 221ms/step - loss: 1.8769 - acc: 0.4872 - val_loss: 2.6034 - val_acc: 0.3996\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 11/50\n",
      "447/447 [==============================] - 105s 235ms/step - loss: 1.9068 - acc: 0.4889 - val_loss: 2.3859 - val_acc: 0.3967\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 12/50\n",
      "447/447 [==============================] - 100s 224ms/step - loss: 1.9161 - acc: 0.4828 - val_loss: 2.5729 - val_acc: 0.3553\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=7599 // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2052 // validation_generator.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=cb,\n",
    "    max_queue_size=2 * train_generator.batch_size,\n",
    "    use_multiprocessing = True,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "model.load_weights(\"lemurnet_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "# make block_16_expand and subsequent layers trainable for fine-tuning\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == \"block_15_expand\":\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-5),\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        \"lemurnet_mobilenet_finetuning.h5\",\n",
    "        monitor=\"val_acc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.EarlyStopping(monitor=\"val_acc\", patience=5, verbose=1),\n",
    "    callbacks.TensorBoard(log_dir=\"./logs_finetuning\", write_images=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_acc\", factor=0.5, patience=1, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "447/447 [==============================] - 115s 257ms/step - loss: 1.7683 - acc: 0.5119 - val_loss: 2.1330 - val_acc: 0.4620\n",
      "Epoch 2/50\n",
      "447/447 [==============================] - 101s 227ms/step - loss: 1.5590 - acc: 0.5474 - val_loss: 2.1703 - val_acc: 0.4488\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 3/50\n",
      "447/447 [==============================] - 103s 230ms/step - loss: 1.5529 - acc: 0.5553 - val_loss: 2.1528 - val_acc: 0.4644\n",
      "Epoch 4/50\n",
      "447/447 [==============================] - 99s 221ms/step - loss: 1.4711 - acc: 0.5772 - val_loss: 2.1557 - val_acc: 0.4479\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 5/50\n",
      "447/447 [==============================] - 102s 228ms/step - loss: 1.4255 - acc: 0.5922 - val_loss: 1.9970 - val_acc: 0.4776\n",
      "Epoch 6/50\n",
      "447/447 [==============================] - 101s 225ms/step - loss: 1.4572 - acc: 0.5739 - val_loss: 2.1465 - val_acc: 0.4825\n",
      "Epoch 7/50\n",
      "447/447 [==============================] - 103s 230ms/step - loss: 1.3950 - acc: 0.6002 - val_loss: 2.2330 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "Epoch 8/50\n",
      "447/447 [==============================] - 104s 232ms/step - loss: 1.4967 - acc: 0.5790 - val_loss: 1.9991 - val_acc: 0.4854\n",
      "Epoch 9/50\n",
      "447/447 [==============================] - 102s 229ms/step - loss: 1.3222 - acc: 0.6182 - val_loss: 2.1198 - val_acc: 0.4859\n",
      "Epoch 10/50\n",
      "447/447 [==============================] - 101s 225ms/step - loss: 1.6970 - acc: 0.5215 - val_loss: 1.9958 - val_acc: 0.4917\n",
      "Epoch 11/50\n",
      "447/447 [==============================] - 105s 235ms/step - loss: 1.6865 - acc: 0.5277 - val_loss: 1.9908 - val_acc: 0.4849\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
      "Epoch 12/50\n",
      "447/447 [==============================] - 101s 227ms/step - loss: 1.7179 - acc: 0.5232 - val_loss: 2.1851 - val_acc: 0.4391\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\n",
      "Epoch 13/50\n",
      "447/447 [==============================] - 101s 225ms/step - loss: 1.7219 - acc: 0.5164 - val_loss: 2.0197 - val_acc: 0.4732\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\n",
      "Epoch 14/50\n",
      "447/447 [==============================] - 105s 234ms/step - loss: 1.6156 - acc: 0.5407 - val_loss: 2.0123 - val_acc: 0.4917\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\n",
      "Epoch 15/50\n",
      "447/447 [==============================] - 105s 235ms/step - loss: 1.6876 - acc: 0.5322 - val_loss: 2.1089 - val_acc: 0.4771\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-08.\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=7599 // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2052 // validation_generator.batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=cb,\n",
    "    max_queue_size=2 * train_generator.batch_size,\n",
    "    use_multiprocessing = True,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "model.load_weights(\"lemurnet_mobilenet_finetuning.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save(\"lemurnet.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
